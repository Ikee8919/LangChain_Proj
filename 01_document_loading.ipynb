{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import DirectoryLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"https://see.stanford.edu/materials/aimlcs229/transcripts/MachineLearning-Lecture01.pdf\")\n",
    "#loader=PyPDFLoader(\"C:\\\\Users\\\\ikram\\\\OneDrive\\\\Desktop\\\\InternTask\\\\MachineLearning-Lecture01.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import NotionDirectoryLoader\n",
    "loader = NotionDirectoryLoader(\"docs/Notion_DB\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = pages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MachineLearning-Lecture01  \n",
      "Instructor (Andrew Ng):  Okay. Good morning. Welcome to CS229, the machine \n",
      "learning class. So what I wanna do today is ju st spend a little time going over the logistics \n",
      "of the class, and then we'll start to  talk a bit about machine learning.  \n",
      "By way of introduction, my name's  Andrew Ng and I'll be instru ctor for this class. And so \n",
      "I personally work in machine learning, and I' ve worked on it for about 15 years now, and \n",
      "I actually think that machine learning i\n"
     ]
    }
   ],
   "source": [
    "print(page.page_content[0:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://see.stanford.edu/materials/aimlcs229/transcripts/MachineLearning-Lecture01.pdf',\n",
       " 'page': 0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    " \n",
    "print(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed and store the texts\n",
    "# Supplying a persist_directory will store the embeddings on disk\n",
    "persist_directory = 'db'\n",
    "\n",
    "## here we are using OpenAI embeddings but in future we will swap out to local embeddings\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "vectordb = Chroma.from_documents(documents=pages, \n",
    "                                 embedding=embedding,\n",
    "                                 persist_directory=persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# persiste the db to disk\n",
    "vectordb.persist()\n",
    "vectordb = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can load the persisted database from disk, and use it as normal. \n",
    "vectordb = Chroma(persist_directory=persist_directory, \n",
    "                  embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.get_relevant_documents(\"what flying autonomous aircraft?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'similarity'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.search_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'k': 2}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.search_kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ikram\\miniconda3\\envs\\pro\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# create the chain to answer questions \n",
    "qa_chain = RetrievalQA.from_chain_type(llm=OpenAI(), \n",
    "                                  chain_type=\"stuff\", \n",
    "                                  retriever=retriever, \n",
    "                                  return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cite sources\n",
    "def process_llm_response(llm_response):\n",
    "    print(llm_response['result'])\n",
    "    print('\\n\\nSources:')\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        print(source.metadata['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What is matlab',\n",
       " 'result': ' MATLAB is a programming language that makes it easy to write code using matrices and perform numerical routines, data manipulation, and plotting. It is commonly used in implementing learning algorithms and is available for purchase or as a free version called Octave. ',\n",
       " 'source_documents': [Document(page_content='those homeworks will be done in either MATLA B or in Octave, which is sort of — I \\nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn\\'t.  \\nSo I guess for those of you that haven\\'t s een MATLAB before, and I know most of you \\nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \\nplot data. And it\\'s sort of an extremely easy to  learn tool to use for implementing a lot of \\nlearning algorithms.  \\nAnd in case some of you want to work on your  own home computer or something if you \\ndon\\'t have a MATLAB license, for the purposes of  this class, there\\'s also — [inaudible] \\nwrite that down [inaudible] MATLAB — there\\' s also a software package called Octave \\nthat you can download for free off the Internet. And it has somewhat fewer features than MATLAB, but it\\'s free, and for the purposes of  this class, it will work for just about \\neverything.  \\nSo actually I, well, so yeah, just a side comment for those of you that haven\\'t seen \\nMATLAB before I guess, once a colleague of mine at a different university, not at \\nStanford, actually teaches another machine l earning course. He\\'s taught it for many years. \\nSo one day, he was in his office, and an old student of his from, lik e, ten years ago came \\ninto his office and he said, \"Oh, professo r, professor, thank you so much for your \\nmachine learning class. I learned so much from it. There\\'s this stuff that I learned in your \\nclass, and I now use every day. And it\\'s help ed me make lots of money, and here\\'s a \\npicture of my big house.\"  \\nSo my friend was very excited. He said, \"W ow. That\\'s great. I\\'m glad to hear this \\nmachine learning stuff was actually useful. So what was it that you learned? Was it \\nlogistic regression? Was it the PCA? Was it the data ne tworks? What was it that you \\nlearned that was so helpful?\" And the student said, \"Oh, it was the MATLAB.\"  \\nSo for those of you that don\\'t know MATLAB yet, I hope you do learn it. It\\'s not hard, \\nand we\\'ll actually have a short MATLAB tutori al in one of the discussion sections for \\nthose of you that don\\'t know it.  \\nOkay. The very last piece of logistical th ing is the discussion s ections. So discussion \\nsections will be taught by the TAs, and atte ndance at discussion sections is optional, \\nalthough they\\'ll also be recorded and televi sed. And we\\'ll use the discussion sections \\nmainly for two things. For the next two or th ree weeks, we\\'ll use the discussion sections \\nto go over the prerequisites to this class or if some of you haven\\'t seen probability or \\nstatistics for a while or maybe algebra, we\\'ll go over those in the discussion sections as a \\nrefresher for those of you that want one.  \\nLater in this quarter, we\\'ll also use the disc ussion sections to go over extensions for the \\nmaterial that I\\'m teaching in the main lectur es. So machine learning is a huge field, and \\nthere are a few extensions that we really want  to teach but didn\\'t have time in the main \\nlectures for.  ', metadata={'page': 8, 'source': 'C:\\\\Users\\\\ikram\\\\OneDrive\\\\Desktop\\\\InternTask\\\\MachineLearning-Lecture01.pdf'}),\n",
       "  Document(page_content='those homeworks will be done in either MATLA B or in Octave, which is sort of — I \\nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn\\'t.  \\nSo I guess for those of you that haven\\'t s een MATLAB before, and I know most of you \\nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \\nplot data. And it\\'s sort of an extremely easy to  learn tool to use for implementing a lot of \\nlearning algorithms.  \\nAnd in case some of you want to work on your  own home computer or something if you \\ndon\\'t have a MATLAB license, for the purposes of  this class, there\\'s also — [inaudible] \\nwrite that down [inaudible] MATLAB — there\\' s also a software package called Octave \\nthat you can download for free off the Internet. And it has somewhat fewer features than MATLAB, but it\\'s free, and for the purposes of  this class, it will work for just about \\neverything.  \\nSo actually I, well, so yeah, just a side comment for those of you that haven\\'t seen \\nMATLAB before I guess, once a colleague of mine at a different university, not at \\nStanford, actually teaches another machine l earning course. He\\'s taught it for many years. \\nSo one day, he was in his office, and an old student of his from, lik e, ten years ago came \\ninto his office and he said, \"Oh, professo r, professor, thank you so much for your \\nmachine learning class. I learned so much from it. There\\'s this stuff that I learned in your \\nclass, and I now use every day. And it\\'s help ed me make lots of money, and here\\'s a \\npicture of my big house.\"  \\nSo my friend was very excited. He said, \"W ow. That\\'s great. I\\'m glad to hear this \\nmachine learning stuff was actually useful. So what was it that you learned? Was it \\nlogistic regression? Was it the PCA? Was it the data ne tworks? What was it that you \\nlearned that was so helpful?\" And the student said, \"Oh, it was the MATLAB.\"  \\nSo for those of you that don\\'t know MATLAB yet, I hope you do learn it. It\\'s not hard, \\nand we\\'ll actually have a short MATLAB tutori al in one of the discussion sections for \\nthose of you that don\\'t know it.  \\nOkay. The very last piece of logistical th ing is the discussion s ections. So discussion \\nsections will be taught by the TAs, and atte ndance at discussion sections is optional, \\nalthough they\\'ll also be recorded and televi sed. And we\\'ll use the discussion sections \\nmainly for two things. For the next two or th ree weeks, we\\'ll use the discussion sections \\nto go over the prerequisites to this class or if some of you haven\\'t seen probability or \\nstatistics for a while or maybe algebra, we\\'ll go over those in the discussion sections as a \\nrefresher for those of you that want one.  \\nLater in this quarter, we\\'ll also use the disc ussion sections to go over extensions for the \\nmaterial that I\\'m teaching in the main lectur es. So machine learning is a huge field, and \\nthere are a few extensions that we really want  to teach but didn\\'t have time in the main \\nlectures for.  ', metadata={'page': 8, 'source': 'https://see.stanford.edu/materials/aimlcs229/transcripts/MachineLearning-Lecture01.pdf'})]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# break it down\n",
    "query = \"What is matlab\"\n",
    "llm_response = qa_chain(query)\n",
    "# process_llm_response(llm_response)\n",
    "llm_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The course being discussed in this context is CS229, a machine learning class taught by instructor Andrew Ng. The course covers the logistics of machine learning and its applications in various fields, and is taught by a team of graduate student teaching assistants. The class is highly interdisciplinary and has a large impact on many industries and applications. \n",
      "\n",
      "\n",
      "Sources:\n",
      "C:\\Users\\ikram\\OneDrive\\Desktop\\InternTask\\MachineLearning-Lecture01.pdf\n",
      "https://see.stanford.edu/materials/aimlcs229/transcripts/MachineLearning-Lecture01.pdf\n"
     ]
    }
   ],
   "source": [
    "query = \"Tell me about the course?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Machine learning is a field of computer science that involves using algorithms and statistical models to allow computers to learn from data without being explicitly programmed. It involves teaching computers to recognize patterns and make decisions based on data, and was first developed in the late 1950s by computer scientist Arthur Samuel.\n",
      "\n",
      "\n",
      "Sources:\n",
      "https://see.stanford.edu/materials/aimlcs229/transcripts/MachineLearning-Lecture01.pdf\n",
      "https://see.stanford.edu/materials/aimlcs229/transcripts/MachineLearning-Lecture01.pdf\n"
     ]
    }
   ],
   "source": [
    "query = \"what is machine learning?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Supervised learning is a type of learning in machine learning where an algorithm is given a dataset with input variables and their corresponding output values, also known as the \"right answers.\" The algorithm then learns the association between the inputs and outputs in order to make predictions for new data.\n",
      "\n",
      "\n",
      "Sources:\n",
      "C:\\Users\\ikram\\OneDrive\\Desktop\\InternTask\\MachineLearning-Lecture01.pdf\n",
      "https://see.stanford.edu/materials/aimlcs229/transcripts/MachineLearning-Lecture01.pdf\n"
     ]
    }
   ],
   "source": [
    "query = \"What is supervised learning?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Andrew Ng is the instructor of the class.\n",
      "\n",
      "\n",
      "Sources:\n",
      "C:\\Users\\ikram\\OneDrive\\Desktop\\InternTask\\MachineLearning-Lecture01.pdf\n",
      "https://see.stanford.edu/materials/aimlcs229/transcripts/MachineLearning-Lecture01.pdf\n"
     ]
    }
   ],
   "source": [
    "query = \"Andrew Ng?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('similarity',\n",
       " <langchain_community.vectorstores.chroma.Chroma at 0x214fc51ffa0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain.retriever.search_type , qa_chain.retriever.vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "{context}\n",
      "\n",
      "Question: {question}\n",
      "Helpful Answer:\n"
     ]
    }
   ],
   "source": [
    "print(qa_chain.combine_documents_chain.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prompt: why we Deleteing the DB\n",
    "\n",
    "To free up space and resources.\n",
    "\n",
    "The `db` directory contains the persisted embeddings of the documents, which can take up a significant amount of space. Deleting the directory will free up this space.\n",
    "\n",
    "Additionally, deleting the directory will force the `vectordb` object to be recreated the next time it is used. This can be helpful if you want to make changes to the way the documents are embedded or if you want to use a different embedding function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyzipper in c:\\users\\ikram\\miniconda3\\envs\\pro\\lib\\site-packages (0.3.6)\n",
      "Requirement already satisfied: pycryptodomex in c:\\users\\ikram\\miniconda3\\envs\\pro\\lib\\site-packages (from pyzipper) (3.20.0)\n"
     ]
    }
   ],
   "source": [
    "# prompt: 'zip' is not recognized as an internal or external command,\n",
    "# operable program or batch file\n",
    "\n",
    "!pip install pyzipper\n",
    "import pyzipper\n",
    "with pyzipper.AESZipFile('db.zip', 'w', compression=pyzipper.ZIP_DEFLATED) as zf:\n",
    "    zf.write('db')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'apt-get' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!apt-get install zip -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to embed documents and create a retriever and QA chain, adjusted for potential missing fields\n",
    "def create_retriever_and_qa_chain(pages):\n",
    "    persist_directory = 'db'\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vectordb = Chroma.from_documents(documents=pages, embedding=embeddings, persist_directory=persist_directory)\n",
    "    retriever = vectordb.as_retriever()\n",
    "    \n",
    "    # Placeholder for creating a combine_documents_chain or similar setup\n",
    "    # combine_documents_chain = ...\n",
    "    \n",
    "    # Adjusted RetrievalQA instantiation\n",
    "    qa_chain = RetrievalQA(llm=OpenAI(), retriever=retriever, return_source_documents=True, combine_documents_chain=...)\n",
    "    \n",
    "    return qa_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ikram\\miniconda3\\envs\\pro\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.0.9 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "persist_directory = 'db'\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "vectordb2 = Chroma(persist_directory=persist_directory, \n",
    "                  embedding_function=embedding,\n",
    "                   )\n",
    "\n",
    "retriever = vectordb2.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ikram\\miniconda3\\envs\\pro\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# Set up the turbo LLM\n",
    "turbo_llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model_name='gpt-3.5-turbo'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the chain to answer questions \n",
    "qa_chain = RetrievalQA.from_chain_type(llm=turbo_llm, \n",
    "                                  chain_type=\"stuff\", \n",
    "                                  retriever=retriever, \n",
    "                                  return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cite sources\n",
    "def process_llm_response(llm_response):\n",
    "    print(llm_response['result'])\n",
    "    print('\\n\\nSources:')\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        print(source.metadata['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coursera is an online platform that offers courses, specializations, and degrees from various universities and institutions. It provides a wide range of topics, including machine learning, data science, business, and many others. Students can enroll in courses, complete assignments, and earn certificates or degrees upon completion.\n",
      "\n",
      "\n",
      "Sources:\n",
      "https://see.stanford.edu/materials/aimlcs229/transcripts/MachineLearning-Lecture01.pdf\n",
      "C:\\Users\\ikram\\OneDrive\\Desktop\\InternTask\\MachineLearning-Lecture01.pdf\n"
     ]
    }
   ],
   "source": [
    "# full example\n",
    "query = \"what is coursera?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use the following pieces of context to answer the user's question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "{context}\n"
     ]
    }
   ],
   "source": [
    "print(qa_chain.combine_documents_chain.llm_chain.prompt.messages[0].prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{question}\n"
     ]
    }
   ],
   "source": [
    "print(qa_chain.combine_documents_chain.llm_chain.prompt.messages[1].prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
